---
title: "2020 Overwatch League Analysis"
output: html
format:
  html:
    code-fold: true
    code-summary: "Show the code"
---

```{r setup, include=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(plotly)
library(sf)
library(rnaturalearth)
library(shiny)
library(caret)
library(randomForest)
library(gbm)


knitr::opts_chunk$set(warning = FALSE)
```

## Introduction to Overwatch (2020)

Overwatch, a vibrant, team-based shooter game, features a mix of characters each with unique abilities. In 2020, Overwatch League's gameplay involved teams of six engaging in dynamic 6v6 combat across various maps and objectives.

The game categorizes characters into three roles:

- Tanks: These characters lead the charge, absorbing damage and breaking enemy formations.
- Damage Heroes: They specialize in offensive capabilities, requiring skillful play and strategic positioning.
- Support Heroes: Vital for team survival, they heal, shield, and enhance their team's abilities.

## Overwatch League: 2020 Season Analysis

The analysis focuses on the 2020 Overwatch League season, played on Overwatch's original format with six-player teams. This season is notable for its strategic and player dynamics, providing insight into player performances and tactics before Overwatch transitioned to a 5v5 format in its sequel, Overwatch 2.

The shift to 5v5 in Overwatch 2, particularly impacting the role and balance of Tank characters, offers an interesting contrast to the 2020 season data.

```{r analysis setup, include=FALSE}
# Function to calculate the mode
Mode <- function(x) {
    ux <- unique(x)
    if (length(ux) == 1) {
        return(ux)
    } # If there's only one unique value, return it
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
}

# Load the filtered dataset without "All Heroes"
file_path <- "p2/phs_2020_1_no_all_heroes.csv"
data <- read_csv(file_path)

# Mapping of hero names to their roles
hero_roles <- c(
    "D.Va" = "Tank", "Doomfist" = "Tank", "Junker Queen" = "Tank", "Mauga" = "Tank",
    "Orisa" = "Tank", "Ramattra" = "Tank", "Reinhardt" = "Tank", "Roadhog" = "Tank",
    "Sigma" = "Tank", "Winston" = "Tank", "Wrecking Ball" = "Tank", "Zarya" = "Tank",
    "Ashe" = "Damage", "Bastion" = "Damage", "McCree" = "Damage", "Echo" = "Damage",
    "Genji" = "Damage", "Hanzo" = "Damage", "Junkrat" = "Damage", "Mei" = "Damage",
    "Pharah" = "Damage", "Reaper" = "Damage", "Sojourn" = "Damage",
    "Soldier: 76" = "Damage", "Sombra" = "Damage", "Symmetra" = "Damage",
    "Torbjörn" = "Damage", "Tracer" = "Damage", "Widowmaker" = "Damage",
    "Ana" = "Support", "Baptiste" = "Support", "Brigitte" = "Support",
    "Illari" = "Support", "Kiriko" = "Support", "Lifeweaver" = "Support",
    "Lúcio" = "Support", "Mercy" = "Support", "Moira" = "Support", "Zenyatta" = "Support"
)

# Apply the role mapping to the eliminations data
data <- data %>%
    mutate(role = hero_roles[hero_name])

# Filter the dataset for rows where 'stat_name' is 'Eliminations'
eliminations_data <- filter(data, stat_name == "Eliminations")

# Calculate the average eliminations per game for each player
average_eliminations <- eliminations_data %>%
    group_by(player_name, esports_match_id) %>%
    summarise(avg_elim = mean(stat_amount), .groups = "drop") %>%
    group_by(player_name) %>%
    summarise(average_eliminations = mean(avg_elim), .groups = "drop")

# Determine the most common role for each player
player_roles <- eliminations_data %>%
    group_by(player_name) %>%
    summarise(common_role = Mode(role), .groups = "drop")

# Merge the player roles with the average eliminations
player_impact <- merge(average_eliminations, player_roles, by = "player_name")
```

## Player Performance Analysis

### Top Players by Eliminations

To identify the top players based on average eliminations per game, we have used a bar graph showing the top 20 players alongside the number of games played and sorted by color so we know if one role is better at achieving higher average eliminations than other roles. Including the number of games played can highlight outliers such as ChipSa who ranks number 3 in the league but only played one game all season.

```{r 1}
num_games_per_player <- eliminations_data %>%
    group_by(player_name) %>%
    summarise(num_games = n_distinct(esports_match_id), .groups = "drop")

player_impact <- merge(player_impact, num_games_per_player, by = "player_name")

top_20_players <- player_impact %>%
    arrange(desc(average_eliminations)) %>%
    slice_head(n = 20)

top_20_players$dummy_legend <- "Number of Games"

ggplot(top_20_players, aes(x = reorder(player_name, average_eliminations), y = average_eliminations, fill = common_role)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = num_games, color = dummy_legend), hjust = -0.3, vjust = 0.5, position = position_dodge(width = 0.9)) +
    scale_fill_manual(values = c("Tank" = "blue", "Damage" = "red", "Support" = "green")) +
    scale_color_manual(values = "black", name = "", labels = "Number of Games") +
    coord_flip() +
    theme_minimal() +
    labs(x = "Player Name", y = "Average Eliminations Per Game", fill = "Player Role", title = "Top 20 Players by Average Eliminations Per Game") +
    theme(legend.position = "bottom", legend.title.align = 0.5)
```

### Top Players in each Role Compared

Again we use a bar graph to identify the top players based on elimination average but this time we are separating them into the top 5 based on role. This gives us a much clearer understanding compared with the previous graph that tanks generally have higher average eliminations while supports have the lowest.

```{r 5}
# Calculate the number of games for each player
num_games_per_player <- eliminations_data %>%
    group_by(player_name) %>%
    summarise(num_games = n_distinct(esports_match_id), .groups = "drop")

# Get the top 5 players within each role separately
top_players_by_role <- eliminations_data %>%
    group_by(role, player_name) %>%
    summarise(average_eliminations = mean(stat_amount, na.rm = TRUE), .groups = "drop") %>%
    group_by(role) %>% # Ensure the slicing is done within each role
    slice_max(order_by = average_eliminations, n = 5, with_ties = FALSE) %>%
    ungroup() %>%
    arrange(role, desc(average_eliminations))

# Merge this information with the number of games
top_players_by_role <- merge(top_players_by_role, num_games_per_player, by = "player_name")

# Create a dummy variable for the legend (for the number of games)
top_players_by_role$dummy_legend <- "Number of Games"

ggplot(top_players_by_role, aes(x = reorder(player_name, average_eliminations), y = average_eliminations, fill = role)) +
    geom_bar(stat = "identity", position = position_dodge(width = 0.7)) +
    geom_text(aes(label = num_games, color = dummy_legend), hjust = -0.3, vjust = 0.5, position = position_dodge(width = 0.9)) +
    scale_fill_manual(values = c("Tank" = "blue", "Damage" = "red", "Support" = "green")) +
    scale_color_manual(values = "black", name = "", labels = "Number of Games") +
    coord_flip() +
    labs(title = "Top 5 Players by Average Eliminations within Each Role", x = "Player", y = "Average Eliminations") +
    theme_minimal() +
    theme(legend.position = "bottom", legend.title.align = 0.5)

```

### Top Players in each Role Comparing all Roles played

This graph allows us to see which roles the players from the previous chart played best on in terms of average eliminations. This also gives us a better understanding of how these top players performed over a longer time. by showing their extremes as well as their first and third quartiles.

```{r 7}
# Identifying top 5 players in each role based on average eliminations
top_players_by_role <- eliminations_data %>%
    group_by(player_name, role) %>%
    summarise(average_eliminations = mean(stat_amount, na.rm = TRUE), .groups = "drop") %>%
    group_by(role) %>%
    slice_max(order_by = average_eliminations, n = 5, with_ties = FALSE) %>%
    ungroup() %>%
    select(player_name)

# Subsetting the eliminations_data to include only these top players
top_eliminations_data <- eliminations_data %>%
    semi_join(top_players_by_role, by = "player_name")

# Creating the boxplot with the subsetted data
ggplot(top_eliminations_data, aes(x = player_name, y = stat_amount, fill = role)) +
    geom_boxplot(outlier.shape = NA) + # Optional: Hide outliers
    coord_flip() +
    labs(title = "Boxplot of Eliminations by Top 5 Players in Each Role", x = "Player", y = "Number of Eliminations") +
    scale_fill_manual(values = c("Tank" = "blue", "Damage" = "red", "Support" = "green")) +
    theme_minimal() +
    theme(legend.position = "bottom", axis.text.y = element_text(size = 7))

```

## Hero Performace Analysis

### Hero Elimination Impact

The objective of this graph is to understand which heros stand out when it comes to average eliminations. We can see that Damage and Tank heros generally trend towards the higher end of the graph while Supports who are mostly focused on healing and keeping their team alive have less focus spent on getting eliminations. Moira stands out as a support in the number 3 spot which can be explained by her kit which requires Moira to deal damage to regenerate her healing capibilities.

```{r 2a, output=FALSE}
avg_elim_by_hero <- eliminations_data %>%
    group_by(hero_name, role) %>% # Assuming there's a 'role' column
    summarise(average_eliminations = mean(stat_amount, na.rm = TRUE)) %>%
    ungroup() %>% # Remove grouping
    arrange(desc(average_eliminations))

ggplot(avg_elim_by_hero, aes(x = reorder(hero_name, average_eliminations), y = average_eliminations, fill = role)) +
    geom_bar(stat = "identity") +
    scale_fill_manual(values = c("Tank" = "blue", "Damage" = "red", "Support" = "green")) +
    coord_flip() +
    labs(title = "Average Eliminations by Hero", x = "Hero", y = "Average Eliminations", fill = "Role") +
    theme_minimal() +
    theme(legend.position = "bottom")
```

```{r 2b, echo=FALSE}
ggplot(avg_elim_by_hero, aes(x = reorder(hero_name, average_eliminations), y = average_eliminations, fill = role)) +
    geom_bar(stat = "identity") +
    scale_fill_manual(values = c("Tank" = "blue", "Damage" = "red", "Support" = "green")) +
    coord_flip() +
    labs(title = "Average Eliminations by Hero", x = "Hero", y = "Average Eliminations", fill = "Role") +
    theme_minimal() +
    theme(legend.position = "bottom")
```

### Elimination Distribution

- Objective: Show the distribution of eliminations across roles.
- Clarity: Highlight the differences between Tank, Damage, and Support roles in elimination counts.
- Visual Appeal: Use histograms with distinct colors for each role, adding labels for clarity.

```{r 4}
ggplot(eliminations_data, aes(x = stat_amount, fill = role)) +
    geom_histogram(bins = 30, alpha = 0.7) +
    labs(title = "Elimination Count Distribution by Role", x = "Number of Eliminations", y = "Frequency") +
    scale_fill_manual(values = c("Tank" = "blue", "Damage" = "red", "Support" = "green")) +
    theme_minimal()
```

### Hero Performance by Elimination Boxplot

- Objective: Analyze hero performance variability using eliminations as a metric.
- Gestalt Principle: Leverage enclosure and similarity in boxplots to compare hero performance.
- Annotation: Highlight heroes with exceptional performance or limited effectiveness.

```{r 6}
ggplot(eliminations_data, aes(x = hero_name, y = stat_amount, fill = role)) +
    geom_boxplot() +
    coord_flip() +
    labs(title = "Boxplot of Eliminations by Hero", x = "Hero", y = "Number of Eliminations") +
    theme_minimal()
```

### Role Performance Boxplot

- Objective: Examine the overall performance of each role through the season.
- Design: Implement boxplots with role-based color coding for clear role comparison.
- Context: Provide insights into the balance between Damage and Tank roles.

```{r 8}
ggplot(eliminations_data, aes(x = role, y = stat_amount, fill = role)) +
    geom_boxplot() +
    labs(title = "Boxplot of Eliminations by Role", x = "Role", y = "Number of Eliminations") +
    scale_fill_manual(values = c("Tank" = "blue", "Damage" = "red", "Support" = "green")) +
    theme_minimal()
```

### Average Eliminations by Role

- Objective: Compare average eliminations across different roles.
- Insight: Emphasize the surprising performance of Tank heroes over Damage heroes, reflecting the season's META.
- Design: Ensure clear role distinction using color and concise legends.

```{r 3}
avg_elim_by_role <- eliminations_data %>%
    group_by(role) %>%
    summarise(average_eliminations = mean(stat_amount, na.rm = TRUE)) %>%
    arrange(desc(average_eliminations))

ggplot(avg_elim_by_role, aes(x = role, y = average_eliminations, fill = role)) +
    geom_bar(stat = "identity") +
    labs(title = "Average Eliminations by Role", x = "Role", y = "Average Eliminations") +
    scale_fill_manual(values = c("Tank" = "blue", "Damage" = "red", "Support" = "green")) +
    theme_minimal()
```

## General Analysises

### Map-Specific Hero Picks

- Objective: Identify trends in hero selection across different maps.
- Visual Approach: Use a heat map to indicate the frequency of hero picks per map.
- Additional Information: Include annotations on unusual map-specific picks or general hero popularity.

```{r 9}
hero_picks_count <- data %>%
    group_by(esports_match_id, map_name, hero_name) %>%
    summarise(count = n(), .groups = "drop") %>%
    ungroup()

hero_picks_aggregated <- hero_picks_count %>%
    group_by(map_name, hero_name) %>%
    summarise(total_count = sum(count), .groups = "drop")

hero_picks_wide <- hero_picks_aggregated %>%
    pivot_wider(names_from = map_name, values_from = total_count, values_fill = list(total_count = 0))

hero_picks_long <- hero_picks_wide %>%
    gather(key = "map_name", value = "pick_count", -hero_name)

ggplot(hero_picks_long, aes(x = map_name, y = hero_name, fill = pick_count)) +
    geom_tile(color = "white") +
    scale_fill_gradient(low = "white", high = "steelblue") +
    labs(title = "Hero Picks on Different Maps", x = "Map", y = "Hero") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

### Seasonal Elimination Trends

- Objective: Track the progression of eliminations throughout the season.
- Design: Employ a line graph to depict the temporal trend of eliminations.
- Context: Highlight matches with unusually high eliminations as potential points of interest for fans and scouts.

```{r 10}
# Convert 'start_time' to a Date object if it's not already
eliminations_data <- eliminations_data %>%
    mutate(date = as.Date(start_time)) %>%
    arrange(date) %>%
    group_by(date) %>%
    summarise(daily_eliminations = sum(stat_amount), .groups = "drop") %>%
    mutate(cumulative_eliminations = cumsum(daily_eliminations))

# Create the plot
ggplot(eliminations_data, aes(x = date, y = cumulative_eliminations)) +
    geom_line() + # Use geom_line for a line plot
    labs(
        title = "Rolling Total Number of Eliminations Over Time",
        x = "Date by Month",
        y = "Cumulative Eliminations"
    ) +
    theme_minimal()
```

## Machine Learning

### Python
```{python ml, eval = FALSE}
# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
import numpy as np

# Load the dataset
data = pd.read_csv("p2/merged_esports_data_updated.csv")

# Preprocess the data (fill missing values, one-hot encoding)
data = data.fillna(data.median(numeric_only=True))
data = pd.get_dummies(data, columns=["map_type", "map_name", "player_name", "team_name", "hero_name"])

# Drop irrelevant columns
data = data.drop(columns=["team_one_name", "team_two_name", "match_id"])

# Split the data into features and target
X = data.drop("match_winner", axis=1)
y = data["match_winner"]

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train models
lr_model = LogisticRegression().fit(X_train, y_train)
rf_model = RandomForestClassifier(n_estimators=50, random_state=42).fit(X_train, y_train)
gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42).fit(X_train, y_train)

# Predictions and Evaluation
predictions_lr = lr_model.predict(X_test)
predictions_rf = rf_model.predict(X_test)
predictions_gb = gb_model.predict(X_test)

# Save predictions and true values for R
results = pd.DataFrame({
    "y_test": y_test,
    "predictions_lr": predictions_lr,
    "predictions_rf": predictions_rf,
    "predictions_gb": predictions_gb
})
results.to_csv("model_results.csv", index=False)

# Save feature importances for R
feature_importances = pd.DataFrame({
    "feature": X.columns,
    "importance_rf": rf_model.feature_importances_,
    "importance_gb": gb_model.feature_importances_
})
feature_importances.to_csv("feature_importances.csv", index=False)

```

### R
```{r ml2}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(caret)
library(reshape2)

# Read the model results and feature importances
results <- read.csv("p2/model_results.csv")
feature_importances <- read.csv("p2/feature_importances.csv")

# Selecting the top 10 important features for each model
top_features_rf <- feature_importances %>%
                   arrange(desc(importance_rf)) %>%
                   head(10)

top_features_gb <- feature_importances %>%
                   arrange(desc(importance_gb)) %>%
                   head(10)

# Plotting feature importances
# For Random Forest
ggplot(top_features_rf, aes(x = reorder(feature, importance_rf), y = importance_rf)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(title = "Top 10 Feature Importances - Random Forest")

# For Gradient Boosting
ggplot(top_features_gb, aes(x = reorder(feature, importance_gb), y = importance_gb)) +
    geom_bar(stat = "identity") +
    coord_flip() +
    labs(title = "Top 10 Feature Importances - Gradient Boosting")

# Confusion matrices and performance metrics
# Logistic Regression
cm_lr <- confusionMatrix(as.factor(results$predictions_lr), as.factor(results$y_test))
metrics_lr <- data.frame(Model = "Logistic Regression", Accuracy = cm_lr$overall['Accuracy'], Sensitivity = cm_lr$byClass['Sensitivity'], Specificity = cm_lr$byClass['Specificity'])

# Random Forest
cm_rf <- confusionMatrix(as.factor(results$predictions_rf), as.factor(results$y_test))
metrics_rf <- data.frame(Model = "Random Forest", Accuracy = cm_rf$overall['Accuracy'], Sensitivity = cm_rf$byClass['Sensitivity'], Specificity = cm_rf$byClass['Specificity'])

# Gradient Boosting
cm_gb <- confusionMatrix(as.factor(results$predictions_gb), as.factor(results$y_test))
metrics_gb <- data.frame(Model = "Gradient Boosting", Accuracy = cm_gb$overall['Accuracy'], Sensitivity = cm_gb$byClass['Sensitivity'], Specificity = cm_gb$byClass['Specificity'])

# Combine metrics and melt for ggplot
combined_metrics <- rbind(metrics_lr, metrics_rf, metrics_gb)
melted_metrics <- melt(combined_metrics, id.vars = "Model")

# Bar plot of accuracy, sensitivity, and specificity for each model
ggplot(melted_metrics, aes(x = variable, y = value, fill = Model)) +
    geom_bar(stat = "identity", position = position_dodge()) +
    facet_wrap(~Model) +
    scale_fill_brewer(palette = "Set1") +
    labs(x = "Metric", y = "Value", title = "Model Performance Comparison") +
    theme_minimal()

```